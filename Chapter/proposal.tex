\chapter{Proposed Work}\label{cap:proposal}
\thispagestyle{empty}

	%Investigate if leveraging IXPs as scalable vantage points, performing measure- ments campaigns from IXP to the outside Internet, and using available privileged data (i.e., flows samples and BGP information) can improve the interconnection mapping to facilities and create a broader, more accurate and scalable methodology which would be used to enhance network infrastructure and safety. Investigate if using IXPs as vantage points could improve the initial IXP/AS to facility mapping through measurements in- stead of relying on online resources (PeeringDB, IXPs/ASes websites).

	Based on studies on the characteristics of Internet Exchange Points, it is shown that they are promising candidates for the emergence of new solutions involving Internet mapping. Their central roles in topology enable higher visibility and knowledge about the network, showing potential in generating geolocation inferences.

	This Ph.D. work plan seeks to investigate new techniques to explore IXPs as anchors to improve the Internet mapping and generate geolocation inferences of peering interconnections and topology elements. Our goal is to develop a precise and systematic approach to increase geolocation knowledge while making it scalable, automatized, and low-cost and examine the accuracy of using these infrastructures as vantage points. We plan to produce a tool that can be used by researchers for the development of new researches and by network operators to apply to practical situations.

	First, we aim to enhance geolocation inferences in developing regions such as Latin America, which show rich, but weakly examined, peering infrastructures~\cite{IXbr, DissectingBrazilianIXP}. Next, we aim to extend our methodology to other worldwide available IXPs and develop a better understanding of the geolocation characteristics of these infrastructures in the Internet Topology.


	\textbf{Data to be used.} To reach these goals, we will use different data sources publicly available. We will employ targeted traceroutes performed by IXPs as anchors at scale along with BGP information. In order to improve our measurements, we will also leverage other vantage points as RIPE Atlas~\cite{ripeatlas}, Looking Glass (Periscope \cite{Periscope}) and CAIDA Ark~\cite{ark}. To obtain information about peering infrastructures, we will use datasets as PeeringDB~\cite{peeringDB}, PCH~\cite{pch}, Inflect~\cite{inflect}, IXP, ASes, and Network Operating Centers (NOCs) websites and lists provided in regional consortia of IXPs.

	%\textbf{Data to be used.} We can use data sources as PeeringDB, PCH, DataCenterMap, Inflect Data Center and Peering Mapping (https://inflect.com), IXP, ASes, and Network Operating Centers (NOCs) websites and lists provided in regional consortia of IXPs, as well as active measurements using the IXP as a vantage point to build a mapping between AS, IXP, and facilities. We can use other vantage points as RIPE Atlas, Looking Glass (Periscope \cite{Periscope}), iPlane and CAIDA Ark to augment our mapping or to validate the mapping obtained from the IXP point of view. We can use datasets of BGP to leverage the BGP Communities attribute and acquire accurate location information for about half of all BGP IPv4 updates as \cite{Giotsas:2017:DPI:3098822.3098855}. We can use flow sample datasets from IX.br to investigate how many IXPs a given flow is traversing, infer and "see" from where traffic arrives, leaves, where it comes from. Also to obtain the ground truth of this IXPâ€™s public peering fabric, map MAC addresses to router IP addresses and their respective AS numbers~\cite{Ager:2012} and information about how two parties of an IXP peering use that link and for what purpose~\cite{Richter:2014}.

	%\textbf{Assumptions.} 

	\textbf{Data processing and implementation} The collection of control plane information (BGP) and measurements campaigns tends to generate a significant amount of data. In order to process all data efficiently and without imposing resource and performance overheads to the IXP, we plan to use cloud environments (e.g., Azure) capable of dealing with a massive volume of data.

	%\textbf{Set of metrics.} Number of peering interfaces inferred. Fraction of resolved interfaces when dealing with less vantage points used. Fraction of unresolved interfaces with when removing facilities information. Fraction of ground truth locations that match inferred locations. \cite{Giotsas:2015:MPI:2716281.2836122}. Number of peering interfaces inferred by one IXP. Error probability of inferred location.

	\textbf{Validation.} To validate the obtained results, we plan to contact network operators, IXPs and ASes to generate a ground truth dataset. To improve the validations, we intend to use privileged data from inside the IXPs as flow samples and BGP information and leverage other sources of data as BGP communities.

	\textbf{Risks and limitations.} There are a few challenges and risks in the proposed research. Due to the low representation of existing measurement projects in developing areas (e.g., Latin America), there could be gaps in infrastructure and methodologies which could affect our geolocation inferences. We could face performance problems as IXPs not being good vantage points (VP) to improve Internet mapping or providing inaccurate results when using few IXPs given that their visibility, individually, may not perfect. Besides that, we could also face bureaucratic challenges as IXPs could not see a clear advantage of being used as VPs.

	\textbf{Research Questions.} In this work, we aim to answer the following research questions: Can IXPs be used as vantage points to generate geolocation inferences about peering interconnections and Internet topology? What and how many are necessary to have a precise vision of the Internet? What are the implications of using this approach concerning computational cost, network traffic, and privacy? Can we discover gaps in physical and measurements (BGP) infrastructure? How can new data sources improve the Internet mapping? Is it possible to be precise using less information than related work? How is it possible to measure in a scalable and automatized way?
